{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Train and Test Data.\n",
    "df_tr = pd.read_csv('Data\\Intrusion-Detection\\Train_data.csv',na_values='?',header=0)\n",
    "df_tr.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = pd.read_csv('Data\\Intrusion-Detection\\Test_data.csv',na_values='?',header=0)\n",
    "df_ts.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Duplicates\n",
    "df_tr.drop_duplicates(keep='first')\n",
    "df_ts.drop_duplicates(keep='first')\n",
    "\n",
    "#Drop NA\n",
    "df_tr.dropna()\n",
    "df_ts.dropna()\n",
    "\n",
    "#Drop ClassLabel column from input array X and Create output array y of Classlabel.\n",
    "Xtr = np.array(df_tr.drop('xAttack',axis=1))\n",
    "ytr = np.array(df_tr['xAttack'])\n",
    "Xts = np.array(df_ts.drop('xAttack',axis=1))\n",
    "yts = np.array(df_ts['xAttack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Duplicates\n",
    "df_tr.drop_duplicates(keep='first')\n",
    "df_ts.drop_duplicates(keep='first')\n",
    "\n",
    "#Drop NA\n",
    "df_tr.dropna()\n",
    "df_ts.dropna()\n",
    "\n",
    "#Drop ClassLabel column from input array X and Create output array y of Classlabel.\n",
    "Xtr = np.array(df_tr.drop('xAttack',axis=1))\n",
    "ytr = np.array(df_tr['xAttack'])\n",
    "Xts = np.array(df_ts.drop('xAttack',axis=1))\n",
    "yts = np.array(df_ts['xAttack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr[:,1] = le.fit_transform(Xtr[:,1])\n",
    "Xts[:,2] = le.fit_transform(Xts[:,2])\n",
    "Xts = np.delete(Xts,0,axis=1)\n",
    "\n",
    "ytr = le.fit_transform(ytr)\n",
    "lb.fit_transform(ytr)\n",
    "\n",
    "yts = le.fit_transform(yts)\n",
    "lb.fit_transform(yts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xtr)\n",
    "Xtr_t = scaler.transform(Xtr)\n",
    "Xts_t = scaler.transform(Xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xtr)\n",
    "Xtr_t = scaler.transform(Xtr)\n",
    "Xts_t = scaler.transform(Xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot PoV\n",
    "S = pca.singular_values_\n",
    "\n",
    "lam = S**2\n",
    "PoV = np.cumsum(lam)/np.sum(lam)\n",
    "\n",
    "plt.plot(PoV)\n",
    "plt.xlabel('No. of PCs')\n",
    "plt.ylabel('PoV')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the classes, considering two features\n",
    "cls1 = (ytr==0)\n",
    "cls2 = (ytr==1)\n",
    "cls3 = (ytr==2)\n",
    "cls4 = (ytr==3)\n",
    "cls5 = (ytr==4)\n",
    "\n",
    "plt.scatter(Ztr[cls2,0],Ztr[cls2,1],color='g')\n",
    "plt.scatter(Ztr[cls1,0],Ztr[cls1,1],color='r')\n",
    "plt.scatter(Ztr[cls3,0],Ztr[cls3,1],color='b')\n",
    "plt.scatter(Ztr[cls4,0],Ztr[cls4,1],color='y')\n",
    "plt.scatter(Ztr[cls5,0],Ztr[cls5,1],color='c')\n",
    "plt.grid()\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend(['Normal','DoS','Probe','R2L','U2R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp =20\n",
    "# Construct the PCA object\n",
    "pca = PCA(n_components=ncomp, \n",
    "          svd_solver='randomized', whiten=True)\n",
    "\n",
    "# Fit the PCA components on the entire dataset\n",
    "pca.fit(Xtr_t)\n",
    "Ztr = pca.transform(Xtr_t)\n",
    "Zts = pca.transform(Xts_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "logreg.fit(Ztr,ytr)\n",
    "yhat = logreg.predict(Zts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(yhat == yts)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use cross validation to find out the optimal number of PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test = np.arange(2,41)\n",
    "acc = []\n",
    "\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "    pca = PCA(n_components=ncomp)\n",
    "    pca.fit(Xtr_t)\n",
    "    Ztr = pca.transform(Xtr_t)\n",
    "    Zts = pca.transform(Xts_t)\n",
    "    \n",
    "    logreg = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "    logreg.fit(Ztr,ytr)\n",
    "    \n",
    "    yhat = logreg.predict(Zts)\n",
    "    acci = np.mean(yhat==yts)\n",
    "    acc.append(acci)\n",
    "\n",
    "imax = np.argmax(acc)\n",
    "accuracy = acc[imax]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optPCA = ncomp_test[imax]\n",
    "print('Optimal PCs:',optPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp =32\n",
    "pca = PCA(n_components=ncomp, \n",
    "          svd_solver='randomized', whiten=True)\n",
    "\n",
    "pca.fit(Xtr_t)\n",
    "Ztr = pca.transform(Xtr_t)\n",
    "Zts = pca.transform(Xts_t)\n",
    "\n",
    "logreg = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "logreg.fit(Ztr,ytr)\n",
    "yhat_tr = logreg.predict(Ztr)\n",
    "acc_tr = np.mean(yhat_tr==ytr)\n",
    "print('Train Accuracy:',acc_tr)\n",
    "\n",
    "yhat_ts = logreg.predict(Zts)\n",
    "acc_ts = np.mean(yhat_ts==yts)\n",
    "print('Tesy Accuracy:',acc_ts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
